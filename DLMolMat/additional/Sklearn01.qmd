---
title: Regresi sederhana dengan sklearn
lang: id
language:
  id:
    crossref-eq-prefix: Persamaan
    section-title-abstract: Abstrak
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
```

```{python}
import matplotlib_inline
matplotlib_inline.backend_inline.set_matplotlib_formats("svg")
```

```{python}
matplotlib.style.use("dark_background")
matplotlib.rcParams.update({
    "axes.grid" : True,
    "grid.color": "gray",
    "grid.linestyle": "--"
})
```


# Regresi linear

Model linear
$$
\mathbf{y} = \mathbf{X}\mathbf{w}
$$

Matriks input:
$$
\mathbf{X} = \begin{bmatrix}
\mathbf{x}^{\mathsf{T}}_{1} \\
\mathbf{x}^{\mathsf{T}}_{2} \\
\vdots \\
\mathbf{x}^{\mathsf{T}}_{N}
\end{bmatrix} =
\begin{bmatrix}
1 & x_{1} & x_{1}^2 & \cdots & x_{1}^{p} \\
1 & x_{2} & x_{2}^2 & \cdots & x_{2}^{p} \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
1 & x_{N} & x_{N}^2 & \cdots & x_{N}^{p} \\
\end{bmatrix}
$$
dengan $p$ adalah derajat polinomial.

Solusi (*normal equation*):
$$
\mathbf{w} = \left(\mathbf{X}^{\mathsf{T}}\mathbf{X} \right)^{-1} \mathbf{X}^{\mathsf{T}} \mathbf{y}
$$ {#eq-w-vektor}

Training / fitting process:
- Input $x$
- buat matriks $\mathbf{X}$
- standard scaling
- fit (solve normal equation)

Prediksi
- Input $x$
- buat matriks $\mathbf{X}$
- standard scaling
- matrix multiplication (dot product) + intercept

# Cara manual

Polinomial derajat tinggi

```{python}
# Polynomial model
def true_model(x):
    return 0.001*(x**10 - x**9) - x**2 + 2

TRUE_DEGREE = 10

def generate_data(noise_amplitude=1.0):
    Ndata = 20
    x = np.linspace(-5.0, 5.0, 20)
    y = true_model(x) + noise_amplitude*np.random.randn(Ndata)
    return x, y

x, y = generate_data(noise_amplitude=100.0)
x_t, y_t = generate_data(noise_amplitude=0.0) # without noise
```

```{python}
plt.plot(x, y, marker="o", linewidth=0, label="data");
plt.plot(x_t, y_t, label="Noiseless");
plt.legend();
```

```{python}
def create_Xmatrix(x, Npoly):
    Ndata = len(x)
    X = np.zeros((Ndata, Npoly+1))
    for i in range(Npoly+1):
        X[:,i] = x**i
    return X
```

```{python}
X = create_Xmatrix(x, TRUE_DEGREE) # TRUE_DEGREE is assumed to be known!
w = np.linalg.inv( X.T @ X ) @ X.T @ y
```

```{python}
w
```

```{python}
X_t = create_Xmatrix(x_t, TRUE_DEGREE)
w_t = np.linalg.pinv( X_t.T @ X_t ) @ X_t.T @ y_t
```

```{python}
w_t
```

```{python}
y_pred = X @ w
```

```{python}
y_pred - y
```

```{python}
X_t @ w_t - y_t
```

```{python}
plt.plot(x, y, linewidth=0, label="data", marker="o")
plt.plot(x, y_pred, label="prediction", marker="o");
plt.ylim(-100, 2000);
plt.legend();
```

```{python}
w
```

# Olympic100m dataset

```{python}
from sklearn.preprocessing import StandardScaler
```

```{python}
data = np.loadtxt("../DATASET/olympic100m.txt", delimiter=",")
```

```{python}
x = data[:,0]
y = data[:,1]
```

```{python}
plt.plot(x, y, marker="o");
plt.xlabel("year");
plt.ylabel("time (s)");
```

```{python}
x_scaled = (x-x[4])/10
X = create_Xmatrix(x_scaled, 10) # create features
w = np.linalg.inv( X.T @ X ) @ X.T @ y
print(w)
y_pred = X @ w
plt.plot(x, y, marker="o", label="data");
plt.plot(x, y_pred, marker="*", label="prediction");
plt.xlabel("year")
plt.ylabel("time (s)");
plt.legend();
```

```{python}
X = create_Xmatrix(x, 10)
w = np.linalg.pinv( X.T @ X ) @ X.T @ y
y_pred = X @ w
plt.plot(x, y, marker="o", label="data");
plt.plot(x, y_pred, marker="*", label="prediction");
plt.xlabel("year")
plt.ylabel("time (s)")
plt.title("10th-degree polynomial (using pinv)")
plt.legend();
```

```{python}
Npoly = 10
x_scaled = (x - x[4])/100
X = create_Xmatrix(x_scaled, Npoly)
w = np.linalg.inv( X.T @ X ) @ X.T @ y
y_pred = X @ w
plt.plot(x, y, marker="o", label="data");
plt.plot(x, y_pred, marker="*", label="prediction");
plt.xlabel("year")
plt.ylabel("time (s)");
plt.title(f"{Npoly}th-degree polynomial (using inv)")
plt.legend();
```

```{python}
Npoly = 4
X = create_Xmatrix(x, Npoly)
```

```{python}
std_scaler.fit_transform(X)
```

```{python}
x
```

# Polynomial feature



# Standard Scaler



# Pipeline


# MLP




